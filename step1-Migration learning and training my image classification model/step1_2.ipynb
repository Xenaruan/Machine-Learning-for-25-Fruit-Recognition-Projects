{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c98888-79c0-4f4c-8e64-b9cc65ac797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: numpy in /environment/miniconda3/lib/python3.10/site-packages (1.24.1)\n",
      "Requirement already satisfied: pandas in /environment/miniconda3/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: matplotlib in /environment/miniconda3/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: seaborn in /environment/miniconda3/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: plotly in /environment/miniconda3/lib/python3.10/site-packages (5.19.0)\n",
      "Requirement already satisfied: requests in /environment/miniconda3/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: tqdm in /environment/miniconda3/lib/python3.10/site-packages (4.65.0)\n",
      "Requirement already satisfied: opencv-python in /environment/miniconda3/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: pillow in /environment/miniconda3/lib/python3.10/site-packages (9.3.0)\n",
      "Requirement already satisfied: wandb in /environment/miniconda3/lib/python3.10/site-packages (0.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /environment/miniconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /environment/miniconda3/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /environment/miniconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /environment/miniconda3/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /environment/miniconda3/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /environment/miniconda3/lib/python3.10/site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /environment/miniconda3/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /environment/miniconda3/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /environment/miniconda3/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /environment/miniconda3/lib/python3.10/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /environment/miniconda3/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /environment/miniconda3/lib/python3.10/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /environment/miniconda3/lib/python3.10/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /environment/miniconda3/lib/python3.10/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (3.1.42)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (1.40.5)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (67.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /environment/miniconda3/lib/python3.10/site-packages (from wandb) (4.23.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /environment/miniconda3/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /environment/miniconda3/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /environment/miniconda3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib seaborn plotly requests tqdm opencv-python pillow wandb -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34acebb-ad33-4775-a842-3df6e4cce3fb",
   "metadata": {},
   "source": [
    "## Download and install Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c9f8de-2c5e-477e-8893-f1435e3ff331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in /environment/miniconda3/lib/python3.10/site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /environment/miniconda3/lib/python3.10/site-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio in /environment/miniconda3/lib/python3.10/site-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: filelock in /environment/miniconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /environment/miniconda3/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /environment/miniconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /environment/miniconda3/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /environment/miniconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /environment/miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.25.0)\n",
      "Requirement already satisfied: lit in /environment/miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: numpy in /environment/miniconda3/lib/python3.10/site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in /environment/miniconda3/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /environment/miniconda3/lib/python3.10/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /environment/miniconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /environment/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /environment/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /environment/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /environment/miniconda3/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /environment/miniconda3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a18e57f9-0ece-4d34-a0fd-0642a778a3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 16:29:54--  https://zihao-openmmlab.obs.cn-east-3.myhuaweicloud.com/20220716-mmclassification/dataset/SimHei.ttf\n",
      "Connecting to 172.16.0.13:5848... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10050868 (9.6M) [application/x-font-ttf]\n",
      "Saving to: ‘SimHei.ttf.2’\n",
      "\n",
      "SimHei.ttf.2        100%[===================>]   9.58M  16.7MB/s    in 0.6s    \n",
      "\n",
      "2024-02-26 16:29:55 (16.7 MB/s) - ‘SimHei.ttf.2’ saved [10050868/10050868]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://zihao-openmmlab.obs.cn-east-3.myhuaweicloud.com/20220716-mmclassification/dataset/SimHei.ttf --no-check-certificate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628a6f7-e356-4d45-95ee-17fcb316b3c7",
   "metadata": {},
   "source": [
    "## Create a catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d149db7a-5f6e-4513-b5c2-72fdf3eb3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a32738-da46-4b63-8b37-8a37dbf79602",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Store the results file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# os.mkdir('output')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Store the trained model weights\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Store the generated charts\u001b[39;00m\n\u001b[1;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagrams\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'checkpoint'"
     ]
    }
   ],
   "source": [
    "# Store the results file\n",
    "# os.mkdir('output')\n",
    "\n",
    "# Store the trained model weights\n",
    "os.mkdir('checkpoint')\n",
    "\n",
    "\n",
    "# Store the generated charts\n",
    "os.mkdir('diagrams')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2dab62-639f-407d-900b-5378a7e631b3",
   "metadata": {},
   "source": [
    "## Setting matplotlib Chinese and English fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a3bcc-5fcf-433d-b9c8-e013de8a1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Font Environment Settings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.font_manager import FontProperties\n",
    " \n",
    "# global font settings\n",
    "SimSun = FontProperties(fname='/home/featurize/SimHei.ttf')  # Used to display Chinese labels normally\n",
    "plt.rcParams['axes.unicode_minus'] = False  # Used to display the negative sign normally\n",
    "Times_New_Roman = FontProperties(fname='/home/featurize/times.ttf')\n",
    " \n",
    "# mixed font settings\n",
    "config = {\n",
    "#     \"font.family\":'serif',\n",
    "#     \"font.size\": 80,\n",
    "       \"mathtext.fontset\":'stix',\n",
    "#     \"font.serif\": ['SimSun'],\n",
    "}\n",
    "rcParams.update(config)\n",
    " \n",
    "#Canvas Settings\n",
    "fig = plt.figure(num=1, figsize=(9, 6),dpi=180)\n",
    "ax = plt.axes((0.23,0.23,0.6,0.6))\n",
    " \n",
    " \n",
    "# Application of font effects \n",
    "ax.set_title('中文宋体 $\\mathrm{Times}$ $\\mathrm{New}$ $\\mathrm{Roman}$ $\\mathrm{123}$'\\\n",
    "                                           ,fontproperties=SimSun,fontsize=12)  \n",
    " \n",
    "ax.set_xlabel('测试测试',fontproperties=SimSun,fontsize=12)                      \n",
    " \n",
    "ax.set_ylabel('TestTest',fontproperties=Times_New_Roman,fontsize=12)            \n",
    " \n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b798af91-3f9b-4e61-8d72-64e79c771eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snap \"tree\" is already installed, see 'snap help refresh'\n"
     ]
    }
   ],
   "source": [
    "!sudo snap install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b07c853-fd23-45ec-9bcc-42c4628aa43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/featurize/data\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mCherryTomatoes\u001b[00m\n",
      "│   ├── \u001b[01;34mMangosteen\u001b[00m\n",
      "│   ├── \u001b[01;34mMomordicaCharantia\u001b[00m\n",
      "│   ├── \u001b[01;34mNavelOrange\u001b[00m\n",
      "│   ├── \u001b[01;34mSandsugaroranges\u001b[00m\n",
      "│   ├── \u001b[01;34mapple\u001b[00m\n",
      "│   ├── \u001b[01;34mbanana\u001b[00m\n",
      "│   ├── \u001b[01;34mcarrot\u001b[00m\n",
      "│   ├── \u001b[01;34mcherries\u001b[00m\n",
      "│   ├── \u001b[01;34mcucumber\u001b[00m\n",
      "│   ├── \u001b[01;34mdurian\u001b[00m\n",
      "│   ├── \u001b[01;34mgrape\u001b[00m\n",
      "│   ├── \u001b[01;34mhamimelon\u001b[00m\n",
      "│   ├── \u001b[01;34mkiwi\u001b[00m\n",
      "│   ├── \u001b[01;34mlemon\u001b[00m\n",
      "│   ├── \u001b[01;34mlichee\u001b[00m\n",
      "│   ├── \u001b[01;34mlongan\u001b[00m\n",
      "│   ├── \u001b[01;34mmango\u001b[00m\n",
      "│   ├── \u001b[01;34mpear\u001b[00m\n",
      "│   ├── \u001b[01;34mpineapple\u001b[00m\n",
      "│   ├── \u001b[01;34mpitaya\u001b[00m\n",
      "│   ├── \u001b[01;34mpomegranate\u001b[00m\n",
      "│   ├── \u001b[01;34mstrawberry\u001b[00m\n",
      "│   ├── \u001b[01;34mtomato\u001b[00m\n",
      "│   └── \u001b[01;34mwatermelon\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    ├── \u001b[01;34mCherrytomatoes\u001b[00m\n",
      "    ├── \u001b[01;34mMangosteen\u001b[00m\n",
      "    ├── \u001b[01;34mMomordicaCharantia\u001b[00m\n",
      "    ├── \u001b[01;34mNavelOrange\u001b[00m\n",
      "    ├── \u001b[01;34mSandsugaroranges\u001b[00m\n",
      "    ├── \u001b[01;34mapple\u001b[00m\n",
      "    ├── \u001b[01;34mbanana\u001b[00m\n",
      "    ├── \u001b[01;34mcarrot\u001b[00m\n",
      "    ├── \u001b[01;34mcherries\u001b[00m\n",
      "    ├── \u001b[01;34mcucumber\u001b[00m\n",
      "    ├── \u001b[01;34mdurian\u001b[00m\n",
      "    ├── \u001b[01;34mgrape\u001b[00m\n",
      "    ├── \u001b[01;34mhamimelon\u001b[00m\n",
      "    ├── \u001b[01;34mkiwi\u001b[00m\n",
      "    ├── \u001b[01;34mlemon\u001b[00m\n",
      "    ├── \u001b[01;34mlichee\u001b[00m\n",
      "    ├── \u001b[01;34mlongan\u001b[00m\n",
      "    ├── \u001b[01;34mmango\u001b[00m\n",
      "    ├── \u001b[01;34mpear\u001b[00m\n",
      "    ├── \u001b[01;34mpineapple\u001b[00m\n",
      "    ├── \u001b[01;34mpitaya\u001b[00m\n",
      "    ├── \u001b[01;34mpomegranate\u001b[00m\n",
      "    ├── \u001b[01;34mstrawberry\u001b[00m\n",
      "    ├── \u001b[01;34mtomato\u001b[00m\n",
      "    └── \u001b[01;34mwatermelon\u001b[00m\n",
      "\n",
      "52 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree /home/featurize/data -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d85e9-0a5e-4371-bdb5-3fc77dba33e4",
   "metadata": {},
   "source": [
    "# change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff01616-4673-486a-808b-3f38a5919258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf8a563-ecab-420d-ba45-31bf235237a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c12d5b0c-f3b8-4a02-97e3-4a16b86558a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Training Set Image Preprocessing - RCTN: Scaling, Cropping, Turn Tensor, Normalisation\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# Test Set Image Preprocessing - RCTN: Scaling, Cropping, Turn Tensor, Normalisation\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72699dd1-416c-4e14-bf88-35bc4eb31a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset folder path\n",
    "dataset_dir = '/home/featurize/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25357cd3-d68f-4537-ba52-8d00b8ce6bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_set_path /home/featurize/data/train\n",
      "Testing_set_path /home/featurize/data/val\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "print('Training_set_path', train_path)\n",
    "print('Testing_set_path', test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c842e36-fe1c-4a52-b282-b9fd98730c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "# Load training set\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "\n",
    "# Load Test Set\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f40ee7-606d-4d21-84af-ec7ca70356a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training set 3649\n",
      "Number of categories 25\n",
      "Name of each category ['CherryTomatoes', 'Mangosteen', 'MomordicaCharantia', 'NavelOrange', 'Sandsugaroranges', 'apple', 'banana', 'carrot', 'cherries', 'cucumber', 'durian', 'grape', 'hamimelon', 'kiwi', 'lemon', 'lichee', 'longan', 'mango', 'pear', 'pineapple', 'pitaya', 'pomegranate', 'strawberry', 'tomato', 'watermelon']\n"
     ]
    }
   ],
   "source": [
    "print('Number of images in the training set', len(train_dataset))\n",
    "print('Number of categories', len(train_dataset.classes))\n",
    "print('Name of each category', train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e13e6282-ba44-4bcb-be67-6104feaf8724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test set images 898\n",
      "Number of categories 25\n",
      "Name of each category ['Cherrytomatoes', 'Mangosteen', 'MomordicaCharantia', 'NavelOrange', 'Sandsugaroranges', 'apple', 'banana', 'carrot', 'cherries', 'cucumber', 'durian', 'grape', 'hamimelon', 'kiwi', 'lemon', 'lichee', 'longan', 'mango', 'pear', 'pineapple', 'pitaya', 'pomegranate', 'strawberry', 'tomato', 'watermelon']\n"
     ]
    }
   ],
   "source": [
    "print('Number of test set images', len(test_dataset))\n",
    "print('Number of categories', len(test_dataset.classes))\n",
    "print('Name of each category', test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7023af2-b62f-4624-b95a-6cff3f47d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of each category\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea80f15-b209-4582-a210-b61314e68ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CherryTomatoes',\n",
       " 'Mangosteen',\n",
       " 'MomordicaCharantia',\n",
       " 'NavelOrange',\n",
       " 'Sandsugaroranges',\n",
       " 'apple',\n",
       " 'banana',\n",
       " 'carrot',\n",
       " 'cherries',\n",
       " 'cucumber',\n",
       " 'durian',\n",
       " 'grape',\n",
       " 'hamimelon',\n",
       " 'kiwi',\n",
       " 'lemon',\n",
       " 'lichee',\n",
       " 'longan',\n",
       " 'mango',\n",
       " 'pear',\n",
       " 'pineapple',\n",
       " 'pitaya',\n",
       " 'pomegranate',\n",
       " 'strawberry',\n",
       " 'tomato',\n",
       " 'watermelon']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37521812-4376-442b-bbe5-f82aaaaee4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CherryTomatoes': 0,\n",
       " 'Mangosteen': 1,\n",
       " 'MomordicaCharantia': 2,\n",
       " 'NavelOrange': 3,\n",
       " 'Sandsugaroranges': 4,\n",
       " 'apple': 5,\n",
       " 'banana': 6,\n",
       " 'carrot': 7,\n",
       " 'cherries': 8,\n",
       " 'cucumber': 9,\n",
       " 'durian': 10,\n",
       " 'grape': 11,\n",
       " 'hamimelon': 12,\n",
       " 'kiwi': 13,\n",
       " 'lemon': 14,\n",
       " 'lichee': 15,\n",
       " 'longan': 16,\n",
       " 'mango': 17,\n",
       " 'pear': 18,\n",
       " 'pineapple': 19,\n",
       " 'pitaya': 20,\n",
       " 'pomegranate': 21,\n",
       " 'strawberry': 22,\n",
       " 'tomato': 23,\n",
       " 'watermelon': 24}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping relationship: category to index number\n",
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a936e1f3-de93-4bc8-acdd-c7f15c7e58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping relationship: index number to category\n",
    "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f988c6c2-507a-4f5a-821b-4dd128956a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'CherryTomatoes',\n",
       " 1: 'Mangosteen',\n",
       " 2: 'MomordicaCharantia',\n",
       " 3: 'NavelOrange',\n",
       " 4: 'Sandsugaroranges',\n",
       " 5: 'apple',\n",
       " 6: 'banana',\n",
       " 7: 'carrot',\n",
       " 8: 'cherries',\n",
       " 9: 'cucumber',\n",
       " 10: 'durian',\n",
       " 11: 'grape',\n",
       " 12: 'hamimelon',\n",
       " 13: 'kiwi',\n",
       " 14: 'lemon',\n",
       " 15: 'lichee',\n",
       " 16: 'longan',\n",
       " 17: 'mango',\n",
       " 18: 'pear',\n",
       " 19: 'pineapple',\n",
       " 20: 'pitaya',\n",
       " 21: 'pomegranate',\n",
       " 22: 'strawberry',\n",
       " 23: 'tomato',\n",
       " 24: 'watermelon'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad78cef0-3875-44b3-a3af-4f31de97fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as local npy file\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139a586-db5a-4cfd-8843-a4efeb0b720a",
   "metadata": {},
   "source": [
    "## Define the data loader DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5227b8a9-a30e-45df-9184-2636e2df14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9f30afd-8ee2-43e9-8287-56c6a397c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data loader for the training set\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "# Data Loader for Test Sets\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae71cdb-3bbb-4a5d-9fd4-bb951e62e8c8",
   "metadata": {},
   "source": [
    "## View images and annotations for a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e26b57a7-a0f9-446b-bef7-016bf6b1c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d446a9-fa67-47b5-920a-ea03f36e5dd6",
   "metadata": {},
   "source": [
    "## Choosing a Transfer Learning Training Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bfa7703-af5e-409c-9b9c-5fdb44ec5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False) # Load only the model structure, not the pre-training weight parameters\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cb757-90af-4853-bfc4-4e3dab9724ff",
   "metadata": {},
   "source": [
    "## Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0cfefca-8a33-456c-b3e0-99068e86e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# Cross Entropy Loss Function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Training rounds Epoch\n",
    "EPOCHS = 30\n",
    "\n",
    "# Learning rate reduction strategies\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d580e4-bb81-4088-b03e-f60f0c99049a",
   "metadata": {},
   "source": [
    "## Functions: training on a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3fab79-74bd-4e8d-a38b-edd0e8c69f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d9cc535-c924-48e7-952f-ca77e3da7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(images, labels):\n",
    "    '''\n",
    "    Run a batch of training and return the training log for the current batch.\n",
    "    '''\n",
    "    \n",
    "    # Get a batch of data and annotations\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images) # Input model to perform forward prediction\n",
    "    loss = criterion(outputs, labels) # Calculate the average cross-entropy loss function value for each sample in the current batch.\n",
    "    \n",
    "    # Optimising update weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Get the label category and prediction category of the current batch\n",
    "    _, preds = torch.max(outputs, 1) # Get the prediction categories for all images in the current batch\n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "    # Calculation of disaggregated assessment indicators\n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
    "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
    "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return log_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e0ff5-db6d-40cd-90a5-ac10a3da3bfe",
   "metadata": {},
   "source": [
    "## Functions: Evaluate on the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26177a58-f1ca-4d84-b570-39f8990614b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "    '''\n",
    "    Evaluate on the entire test set and return a log of categorised evaluation metrics\n",
    "    '''\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader: # Generate a batch of data and annotations\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) # Input model to perform forward prediction\n",
    "\n",
    "            # Get label categories and prediction categories for the entire test set\n",
    "            _, preds = torch.max(outputs, 1) # Get the prediction categories for all images in the current batch\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels) # From logit, calculate the average cross-entropy loss function for each sample in the current batch.\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "        \n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "    \n",
    "    # Calculation of disaggregated assessment indicators\n",
    "    log_test['test_loss'] = np.mean(loss_list)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "    \n",
    "    return log_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98dbf7-2e6a-4b34-ae17-a0ce25d10b2e",
   "metadata": {},
   "source": [
    "## Before training starts, keep a log ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f80597c4-406c-4210-808b-8681da8fb7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "batch_idx = 0\n",
    "best_test_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2156e95-1949-4a4e-8ff4-98af9888ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training log - training sets\n",
    "df_train_log = pd.DataFrame()\n",
    "log_train = {}\n",
    "log_train['epoch'] = 0\n",
    "log_train['batch'] = 0\n",
    "images, labels = next(iter(train_loader))\n",
    "log_train.update(train_one_batch(images, labels))\n",
    "df_train_log = df_train_log._append(log_train, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5872b1e4-ff74-4167-9f94-7040c06f5400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.3938172</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch train_loss  train_accuracy\n",
       "0      0      0  3.3938172         0.03125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b14063dc-ae33-4ad8-9817-04d0f3c75b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training log - test set\n",
    "df_test_log = pd.DataFrame()\n",
    "log_test = {}\n",
    "log_test['epoch'] = 0\n",
    "log_test.update(evaluate_testset())\n",
    "df_test_log = df_test_log._append(log_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ac644ec-237f-4fa6-9976-0a88ebb93556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.697069</td>\n",
       "      <td>0.046771</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.046261</td>\n",
       "      <td>0.01971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  test_loss  test_accuracy  test_precision  test_recall  test_f1-score\n",
       "0    0.0   3.697069       0.046771        0.022265     0.046261        0.01971"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e612e6-c96e-47f4-a1b7-3d0c4e05da96",
   "metadata": {},
   "source": [
    "## Create wandb visualisation project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90754be0-7b52-4174-9e60-2e2a73d60ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af8f0aed-471b-489e-a37b-504943f21a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m13048152760\u001b[0m (\u001b[33mual_student_xintianyin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/featurize/wandb/run-20240226_165721-n415gyvo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ual_student_xintianyin/fruit25/runs/n415gyvo' target=\"_blank\">0226165721</a></strong> to <a href='https://wandb.ai/ual_student_xintianyin/fruit25' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ual_student_xintianyin/fruit25' target=\"_blank\">https://wandb.ai/ual_student_xintianyin/fruit25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ual_student_xintianyin/fruit25/runs/n415gyvo' target=\"_blank\">https://wandb.ai/ual_student_xintianyin/fruit25/runs/n415gyvo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ual_student_xintianyin/fruit25/runs/n415gyvo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f32df1b2980>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='fruit25', name=time.strftime('%m%d%H%M%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce633a-4cfd-4eb5-ac4b-96b8a5891be3",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b7ce321-4961-4837-8c75-0485103903fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the new best model checkpoint/best-0.675.pth\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:05<00:00, 21.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    \n",
    "    ## training phase\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader): # Get a batch of data and annotations\n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)\n",
    "        df_train_log = df_train_log._append(log_train, ignore_index=True)\n",
    "        wandb.log(log_train)\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    ## testing phase\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    df_test_log = df_test_log._append(log_test, ignore_index=True)\n",
    "    wandb.log(log_test)\n",
    "    \n",
    "    # Save the latest best model files\n",
    "    if log_test['test_accuracy'] > best_test_accuracy: \n",
    "        # Delete old best model files (if any)\n",
    "        old_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy)\n",
    "        if os.path.exists(old_best_checkpoint_path):\n",
    "            os.remove(old_best_checkpoint_path)\n",
    "        # Save the new best model file\n",
    "        best_test_accuracy = log_test['test_accuracy']\n",
    "        new_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
    "        torch.save(model, new_best_checkpoint_path)\n",
    "        print('Save the new best model', 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))\n",
    "        # best_test_accuracy = log_test['test_accuracy']\n",
    "\n",
    "df_train_log.to_csv('TraininglogTrainingSets.csv', index=False)\n",
    "df_test_log.to_csv('TrainingLogTestSet.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca998a-11d2-4e4a-a753-8f0419231301",
   "metadata": {},
   "source": [
    "##  Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e709ab8-9741-488b-9834-e335e43e7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model as the current model\n",
    "model = torch.load('checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c826d01-e3b5-4f5b-9458-48470e62d4fb",
   "metadata": {},
   "source": [
    "## Evaluate on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50e8d511-c9cf-4815-8f48-a71389ee8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'test_loss': 1.0977473, 'test_accuracy': 0.6648106904231625, 'test_precision': 0.6735762147736243, 'test_recall': 0.66314819409647, 'test_f1-score': 0.6627346390295513}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(evaluate_testset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
